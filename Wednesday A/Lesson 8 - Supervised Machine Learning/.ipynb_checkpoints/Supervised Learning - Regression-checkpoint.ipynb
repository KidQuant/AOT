{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2aa267d8",
   "metadata": {},
   "source": [
    "# Supervised Learning - Regression\n",
    "\n",
    "In machine learning, linear regression is one of the simplest algorithms that you can apply relationships between features and labels.\n",
    "\n",
    "## Importing the modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cb3cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9030b9a",
   "metadata": {},
   "source": [
    "# A Simple Regression Model\n",
    "\n",
    "First we need to start with a simple linear regression. Linear Regression attempts to model the relationship between different variables. The following shows an example of height and weight.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c366dce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9,6))\n",
    "# represents the heights of a group of people in meters\n",
    "heights = [1.6, 1.65, 1.7, 1.73, 1.8]\n",
    "# represents the weights of a group of people in kgs\n",
    "weights = [60, 65, 72.3, 75, 80]\n",
    "plt.title('Weights plotted against heights')\n",
    "plt.xlabel('Heights in meters')\n",
    "plt.ylabel('Weights in kilograms')\n",
    "plt.plot(heights, weights, 'k.')\n",
    "# axis range for x and y\n",
    "plt.axis([1.5, 1.85, 50, 90])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a10658",
   "metadata": {},
   "source": [
    "There's a positive correlation between the weights and heights for people. We can draw a straight line through the points and use that this to predict the weight of another person based on their height.\n",
    "\n",
    "### Plotting the Linear Regression Line\n",
    "\n",
    "We can use the `Seaborn` and the `scipy` libraries to help use with plotting the regression line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868873f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9, 6))\n",
    "p = sns.regplot(x=heights, y=weights, line_kws={'color': 'red'})\n",
    "slope, intercept, r, p, sterr = scipy.stats.linregress(x=p.get_lines()[0].get_xdata(),\n",
    "                                                       y=p.get_lines()[0].get_ydata())\n",
    "\n",
    "\n",
    "print('Correlation = {}'.format(r))\n",
    "print('Correlation of Determination (R^2) = {}'.format(r**2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7446d9f",
   "metadata": {},
   "source": [
    "The correlation between height and weight is very strong (.99999). We also have the coefficient of determination ($R^2$) of $.999$, which means $99\\%$ of the variability in weight can be explained by the height of a person.\n",
    "\n",
    "The red line represents the smallest average distance of all points. This is known as the regression line, or \"the line of best fit.\" The regression line is given by the following formula.\n",
    "\n",
    "$$\n",
    "\\hat{y}=b_{0}+b_{1}x_{1}\n",
    "$$\n",
    "\n",
    "where $b_{0}$ is the y-intercept, $b_{1}$ is the slope (This is the same equation from algebra!)\n",
    "\n",
    "The formula for the slope, $b_1$, of the best-fitting line is\n",
    "\n",
    "$$\n",
    "b_1=r\\bigg(\\frac{s_y}{s_x}\\bigg)\n",
    "$$\n",
    "\n",
    "Once we have the slope and y-intercept, we can create a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167e8748",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The slope is {}'.format(slope))\n",
    "print('The y-intercept is {}'.format(intercept))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396824ba",
   "metadata": {},
   "source": [
    "The model for our regression line is the following:\n",
    "\n",
    "$$\n",
    "\\hat{y} = -104.75 + 103.31x_1\n",
    "$$\n",
    "\n",
    "We can attempt to predict one our variables for weight $(x_1=1.6)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f19439",
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept + slope * heights[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7cb498",
   "metadata": {},
   "source": [
    "This is pretty close to the actual value of 65. The difference between the actual value $(y_i)$ and the predicted value ($\\hat{y}$) is .70, so the model is pretty accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df483ada",
   "metadata": {},
   "source": [
    "## Multilinear Regression and Machine Learningo\n",
    "\n",
    "Now you will learn about a variant of simple linear regression, called *multiple linear regression*, by predicting house prices based on multiple features.\n",
    "\n",
    "### The Boston Dataset\n",
    "\n",
    "For this example, we will use the Boston dataset, which contains data about the housing and price data in the boston area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8ae023",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"https://raw.githubusercontent.com/scikit-learn/scikit-learn/main/sklearn/datasets/data/boston_house_prices.csv\"\n",
    "df = pd.read_csv(file, header=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e7c1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the names of the potential features\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06f771c",
   "metadata": {},
   "source": [
    "### Attributes of the Features\n",
    "\n",
    "- `CRIM`: per capita crime rate by town\n",
    "- `ZN`: proportion of residential land zoned for lots over 25,000 sq. ft.\n",
    "- `INDUS`: proportion of non-retail business acres per town\n",
    "- `CHAS`: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "- `NOX`: nitric oxides concentration (parts per 10 million)\n",
    "- `RM`: average number of rooms per dweelling\n",
    "- `AGE`: proportion of owner-occupied units built prior to 1940\n",
    "- `DIS`: weighted distance to five Boston employment centres\n",
    "- `RAD`: index of accessibility to radial highway\n",
    "- `TAX`: full-value property-tax rate per $10,000\n",
    "- `PTRATIO`: pupil-teacher ratio by town\n",
    "- `B`: 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "- `LSTAT`: % lower status of the population\n",
    "- `MDEV`: Median value of owner-occupied homes in $1000's\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d035e500",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "The next step would be to clean the data and perform any conversion if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d7598d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d01086",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e11e973",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "We don't want to use all 13 features, as they are all not relevant. Instead, we want to choose features that directly influence the result we are looking for (the price of houses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be78362d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr()\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a1b3a3",
   "metadata": {},
   "source": [
    "This is a lot of data. We can make all of this data more readable by using a heat map visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbec251",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "corr_df = df.corr()\n",
    "sns.heatmap(corr_df, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8f3c9f",
   "metadata": {},
   "source": [
    "Remember, a *positive correlation* is a relationship between two variables in which both variables move together. A *negative correlation* is a relationship between two variables in two variables move in the opposite directions.\n",
    "\n",
    "We want to find variables that move together with the target vartiable `MEDV`. We can see that the variables `LSTAT` and `RM` have the strongest relationship with the `MEDV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8d5e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirms that the features with the strongest relationships with the target.\n",
    "df.corr().abs().nlargest(3, 'MEDV').index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f3c69c",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis (Multiple Regression)\n",
    "\n",
    "We can create a scatter plot with both features in relation with the target variable. We can clearly see that `LSTAT` has a negative correlation with `MEDV` and `RM` has a positive correlation with the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e65b823",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "\n",
    "features = ['LSTAT', 'RM']\n",
    "target = df['MEDV']\n",
    "\n",
    "for i, col in enumerate(features):\n",
    "    plt.subplot(1, len(features), i+1)\n",
    "    x = df[col]\n",
    "    y = target\n",
    "    plt.scatter(x, y, marker='o')\n",
    "    plt.title(col)\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('MEDV')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96397ac",
   "metadata": {},
   "source": [
    "Because we are using two features, we need to create a 3-Dimensional plot to see the relationship. We can do this with the `mpl_toolkits.mplot3d` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb85f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(18,15))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(df['LSTAT'],\n",
    "          df['RM'],\n",
    "          df['MEDV'],\n",
    "          c='b')\n",
    "ax.set_xlabel('LSTAT')\n",
    "ax.set_ylabel('RM')\n",
    "ax.set_zlabel('MEDV')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdae7ad5",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "We begin creating two DataFrames for our features (`LSTAT`,`RM`) and one for our target variable (`MEDV`) and then assigning them to two variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b2b0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(np.c_[df['LSTAT'], df['RM']], columns =['LSTAT', 'RM'])\n",
    "Y = df['MEDV']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9c2a14",
   "metadata": {},
   "source": [
    "We're going to split the dataset into two sets: one for training and one for testing. To do this, we need to use the `train_test_split()` function. \n",
    "\n",
    "We will split the dataset into 70 percent training and 30 percent for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48554b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state =5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e75221f",
   "metadata": {},
   "source": [
    "It's important for our training and testing sets to have the same number of observations. We check this with the `shape` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ce2b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state =5)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0c3d72",
   "metadata": {},
   "source": [
    "Our `X` training set has 354 rows and 2 columns; our `Y` training set has 354 rows and 1 column. \n",
    "\n",
    "Our `X` test set has 152 rows and 2 columns; our `Y` testing set has 152 rows and 1 column.\n",
    "\n",
    "We're now ready to begin training. We're going to use the `LinearRegression` model from `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5e68d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "lin_model = LinearRegression()\n",
    "lin_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d17228",
   "metadata": {},
   "source": [
    "Once the model is trained, we will use the testing set to perform some predictions. We will used the `predict()` function to help us create a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3da523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evaluation for training set\n",
    "y_train_predict = lin_model.predict(X_train)\n",
    "rmse = (np.sqrt(mean_squared_error(Y_train, y_train_predict)))\n",
    "r2 = r2_score(Y_train, y_train_predict)\n",
    "\n",
    "print('The Model performance for training set')\n",
    "print('-'*25)\n",
    "print('RMSE is {}'.format(rmse))\n",
    "print('R2 score is {}'.format(r2))\n",
    "print('\\n')\n",
    "\n",
    "# model evaluation for testing set\n",
    "y_test_predict = lin_model.predict(X_test)\n",
    "rmse = (np.sqrt(mean_squared_error(Y_test, y_test_predict)))\n",
    "r2 = r2_score(Y_test, y_test_predict)\n",
    "\n",
    "print('The model performance for testing set')\n",
    "print('-' * 25)\n",
    "print('RMSE is {}'.format(rmse))\n",
    "print('R2 score is {}'.format(r2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c365bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "sns.regplot(x=Y_test, y=y_test_predict, line_kws={'color': 'red'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075f0d43",
   "metadata": {},
   "source": [
    "### Getting the Intercept and Coefficients\n",
    "\n",
    "Now we can use the information from our predicted values to create a model. Since we are using two features, we need to reformat our regression formula.\n",
    "\n",
    "$$\\hat{y}=\\beta_{0}+\\beta_{1}x_{1}+\\beta_{2}x_{2}$$\n",
    "\n",
    "where $\\hat{y}$ is our target variable, $\\beta_{0}$ is the y-intercept, and $\\beta_{1}$ and $\\beta{2}$ are coefficients for our features $x_1$ and $x_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310e7327",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lin_model.intercept_)\n",
    "print(lin_model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebeaaf9",
   "metadata": {},
   "source": [
    "So our model becomes\n",
    "\n",
    "$$ \\hat{y} = 0.3843 + -0.6595 x_1 + 4.8319 x_2 $$\n",
    "\n",
    "Now we can use this model to make predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf5c2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lin_model.predict([[30, 5]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6807006",
   "metadata": {},
   "source": [
    "Using our model, we can plot the regression line. However, using three variables requires us to use a 3-Dimensional plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c054ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(np.c_[df['LSTAT'], df['RM']], columns = ['LSTAT','RM'])\n",
    "Y = df['MEDV']\n",
    "fig = plt.figure(figsize=(18,15))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(x['LSTAT'],\n",
    "           x['RM'],\n",
    "           Y,\n",
    "           c='b')\n",
    "\n",
    "ax.set_xlabel(\"LSTAT\")\n",
    "ax.set_ylabel(\"RM\")\n",
    "ax.set_zlabel(\"MEDV\")\n",
    "\n",
    "#---create a meshgrid of all the values for LSTAT and RM---\n",
    "\n",
    "x_surf = np.arange(0, 40, 1) #---for LSTAT---\n",
    "y_surf = np.arange(0, 10, 1) #---for RM---\n",
    "x_surf, y_surf = np.meshgrid(x_surf, y_surf)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(x, Y)\n",
    "\n",
    "#---calculate z(MEDC) based on the model---\n",
    "z = lambda x,y: (model.intercept_ + model.coef_[0] * x + model.coef_[1] * y)\n",
    "\n",
    "ax.plot_surface(x_surf, y_surf, z(x_surf,y_surf),\n",
    "                rstride=1,\n",
    "                cstride=1,\n",
    "                color='None',\n",
    "                alpha = 0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4d50cf",
   "metadata": {},
   "source": [
    "As the chart shown in the Notebook is static, we need to save the code snippet into a file named boston.py and run it into a terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2a4f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(lin_model, df[features], df['MEDV'], cv= 5)\n",
    "\n",
    "print('cross-validation scores: {}'.format(scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c40eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Average cross-validation scores: {:.2f}'.format(scores.mean()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
